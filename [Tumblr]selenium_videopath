# encoding=UTF8
import requests
from bs4 import BeautifulSoup
import re
from selenium import webdriver
import time
import random


# 爬取汤不热的片子

def get_content(link, t):
    # 注意这是你要爬取的博主视频链接，下面有一个地方同样需要修改相应的链接
    chromedriver = r'C:\Users\Alex\AppData\Local\Google\Chrome\Application\chromedriver.exe'
    browser = webdriver.Chrome(chromedriver)
    browser.maximize_window()
    browser.get(link)
    # content=r""
    content = []
    n = 0
    while n < 20:
        # if browser.find_element_by_xpath('//*[@class="Knight-Rider-loader centered leviathan"]'):
        browser.execute_script("""(function () {
                    var y = document.body.scrollTop;
                    var step = 100;
                    window.scroll(0, y);


                    function f() {
                        if (y < document.body.scrollHeight) {
                            y += step;
                            window.scroll(0, y);
                            setTimeout(f, 50);
                        }
                        else {
                            window.scroll(0, y);
                            document.title += "scroll-done";
                        }
                    }


                    setTimeout(f, 1000);
                })();   """)
        con = browser.page_source
        time.sleep(5)
        n += 1
        print(n)
        content.append(con)
    return content


def get_url(content):
    for content_text in content:
        soup = BeautifulSoup(content_text)
        tag_list = soup.findAll(['a', 'href'])
        # print(tag_list)
        href_list = []
        for tag in tag_list:
            href_list.append(tag['href'])

        for tag in href_list:
            # 注意这是博主链接
            if r'http://hisb889.tumblr.com/' in tag:
                last = r'.mp4#_=_'
                # print(new_href)
                new_content = requests.get(tag).text
                new_soup = BeautifulSoup(new_content)
                # print(new_content)
                new_tag = new_soup.find(attrs={'property': 'og:image'})
                # print(new_tag['content'])
                ori_href = new_tag['content']
                middle = re.split('_|/', ori_href)[3] + '_' + re.split('_|/', ori_href)[4]
                pre = r'https://vt.tumblr.com/'
                new_path = pre + middle + last
                print(new_path)
            else:
                continue


if __name__ == '__main__':
    href = r'http://hisb889.tumblr.com/archive/filter-by/video'
    t = random.randint(1, 5)
    content = get_content(href, t)
    url_list = get_url(content)
